{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L-aMzQyhLBS0"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path='/content/water.zip'\n",
        "extract_path='/content/water'"
      ],
      "metadata": {
        "id": "Uwniq-XKLIgz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# List the extracted files\n",
        "os.listdir(extract_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spPfCpAnLbjx",
        "outputId": "34760642-85a8-4dde-c21a-563faa2dab72"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dataset']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List files inside the \"dataset\" subfolder\n",
        "dataset_folder = os.path.join(extract_path, \"dataset\")\n",
        "os.listdir(dataset_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNhHSfHvLjJy",
        "outputId": "31c756c6-5cdf-4037-9546-9e46178fd2cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample_submission.csv', 'test.csv', 'train.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "train_df = pd.read_csv(os.path.join(dataset_folder, \"train.csv\"))\n",
        "test_df = pd.read_csv(os.path.join(dataset_folder, \"test.csv\"))\n",
        "sample_submission_df = pd.read_csv(os.path.join(dataset_folder, \"sample_submission.csv\"))"
      ],
      "metadata": {
        "id": "I3xTavvMLpZ-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic info for each dataframe\n",
        "train_info = train_df.info()\n",
        "test_info = test_df.info()\n",
        "sample_submission_head = sample_submission_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06tknyrPMVrA",
        "outputId": "a8c56b7d-24d7-4a28-8633-b753f116e56c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14000 entries, 0 to 13999\n",
            "Data columns (total 12 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Timestamp                 14000 non-null  object \n",
            " 1   Residents                 14000 non-null  int64  \n",
            " 2   Apartment_Type            13574 non-null  object \n",
            " 3   Temperature               13559 non-null  float64\n",
            " 4   Humidity                  14000 non-null  object \n",
            " 5   Water_Price               14000 non-null  float64\n",
            " 6   Period_Consumption_Index  14000 non-null  float64\n",
            " 7   Income_Level              13574 non-null  object \n",
            " 8   Guests                    14000 non-null  int64  \n",
            " 9   Amenities                 8003 non-null   object \n",
            " 10  Appliance_Usage           13585 non-null  float64\n",
            " 11  Water_Consumption         14000 non-null  float64\n",
            "dtypes: float64(5), int64(2), object(5)\n",
            "memory usage: 1.3+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6000 entries, 0 to 5999\n",
            "Data columns (total 11 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Timestamp                 6000 non-null   object \n",
            " 1   Residents                 6000 non-null   int64  \n",
            " 2   Apartment_Type            5834 non-null   object \n",
            " 3   Temperature               5850 non-null   float64\n",
            " 4   Humidity                  6000 non-null   object \n",
            " 5   Water_Price               6000 non-null   float64\n",
            " 6   Period_Consumption_Index  6000 non-null   float64\n",
            " 7   Income_Level              5835 non-null   object \n",
            " 8   Guests                    6000 non-null   int64  \n",
            " 9   Amenities                 3487 non-null   object \n",
            " 10  Appliance_Usage           5823 non-null   float64\n",
            "dtypes: float64(4), int64(2), object(5)\n",
            "memory usage: 515.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show first few rows of the training data\n",
        "train_head = train_df.head()\n",
        "\n",
        "(train_info, test_info, sample_submission_head, train_head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lxp_qbcnMhGW",
        "outputId": "fa990f13-68ee-425b-ab0a-317ea7902740"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,\n",
              " None,\n",
              "        Timestamp  Water_Consumption\n",
              " 0  11/10/2014 16             300.05\n",
              " 1  12/10/2014 00             179.45\n",
              " 2  12/10/2014 08              78.55\n",
              " 3  12/10/2014 16             121.81\n",
              " 4  13/10/2014 00             125.85,\n",
              "        Timestamp  Residents Apartment_Type  Temperature Humidity  Water_Price  \\\n",
              " 0  01/01/2002 00          1         Studio        15.31    46.61         1.06   \n",
              " 1  01/01/2002 08          4            NaN        21.01    66.11         2.98   \n",
              " 2  01/01/2002 16          2        Cottage        12.86    60.86         1.44   \n",
              " 3  02/01/2002 00          2           1BHK        20.16    50.58         1.48   \n",
              " 4  02/01/2002 08          2        Cottage        16.23    52.25         1.14   \n",
              " \n",
              "    Period_Consumption_Index  Income_Level  Guests      Amenities  \\\n",
              " 0                      0.97           Low       0  Swimming Pool   \n",
              " 1                      0.91  Upper Middle       1  Swimming Pool   \n",
              " 2                      1.43        Middle       0            NaN   \n",
              " 3                      0.91        Middle      -1         Garden   \n",
              " 4                      1.11        Middle       0       Fountain   \n",
              " \n",
              "    Appliance_Usage  Water_Consumption  \n",
              " 0              0.0              64.85  \n",
              " 1              1.0             192.50  \n",
              " 2              1.0             116.62  \n",
              " 3              0.0              76.96  \n",
              " 4              0.0             104.70  )"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Processing of data**"
      ],
      "metadata": {
        "id": "WxmdW0wqMua0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-by-step immediate cleaning tasks\n",
        "\n",
        "# 1. Convert 'Humidity' from object to float\n",
        "train_df['Humidity'] = pd.to_numeric(train_df['Humidity'], errors='coerce')\n",
        "test_df['Humidity'] = pd.to_numeric(test_df['Humidity'], errors='coerce')"
      ],
      "metadata": {
        "id": "iIFvUaYqMmKE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Convert 'Timestamp' to datetime\n",
        "train_df['Timestamp'] = pd.to_datetime(train_df['Timestamp'], format=\"%d/%m/%Y %H\")\n",
        "test_df['Timestamp'] = pd.to_datetime(test_df['Timestamp'], format=\"%d/%m/%Y %H\")"
      ],
      "metadata": {
        "id": "DTGJDLSwNDqc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. Extract features from Timestamp: hour, day of week, month\n",
        "for df in [train_df, test_df]:\n",
        "    df['Hour'] = df['Timestamp'].dt.hour\n",
        "    df['DayOfWeek'] = df['Timestamp'].dt.dayofweek\n",
        "    df['Month'] = df['Timestamp'].dt.month"
      ],
      "metadata": {
        "id": "yp5e5NY2NFPC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Check missing values\n",
        "missing_train = train_df.isnull().sum()\n",
        "missing_test = test_df.isnull().sum()\n",
        "\n",
        "# Combine into a DataFrame for easy viewing\n",
        "missing_df = pd.DataFrame({\n",
        "    \"Train Missing\": missing_train,\n",
        "    \"Test Missing\": missing_test\n",
        "})\n",
        "\n",
        "# Display the missing values table\n",
        "print(missing_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lhJ18WONGxC",
        "outputId": "712a6e81-5c3b-4cd1-f3c1-22f3e5b47cd0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          Train Missing  Test Missing\n",
            "Amenities                          5997        2513.0\n",
            "Apartment_Type                      426         166.0\n",
            "Appliance_Usage                     415         177.0\n",
            "DayOfWeek                             0           0.0\n",
            "Guests                                0           0.0\n",
            "Hour                                  0           0.0\n",
            "Humidity                            397         194.0\n",
            "Income_Level                        426         165.0\n",
            "Month                                 0           0.0\n",
            "Period_Consumption_Index              0           0.0\n",
            "Residents                             0           0.0\n",
            "Temperature                         441         150.0\n",
            "Timestamp                             0           0.0\n",
            "Water_Consumption                     0           NaN\n",
            "Water_Price                           0           0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing 'Amenities' with 'Unknown'\n",
        "train_df['Amenities'] = train_df['Amenities'].fillna('Unknown')\n",
        "test_df['Amenities'] = test_df['Amenities'].fillna('Unknown')"
      ],
      "metadata": {
        "id": "fkCi9FMWNHz9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_df['Apartment_Type'] = train_df['Apartment_Type'].fillna(train_df['Apartment_Type'].mode()[0])\n",
        "test_df['Apartment_Type'] = test_df['Apartment_Type'].fillna(train_df['Apartment_Type'].mode()[0])\n",
        "\n",
        "train_df['Income_Level'] = train_df['Income_Level'].fillna(train_df['Income_Level'].mode()[0])\n",
        "test_df['Income_Level'] = test_df['Income_Level'].fillna(train_df['Income_Level'].mode()[0])\n"
      ],
      "metadata": {
        "id": "V7qeOWoUNwy8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in ['Appliance_Usage', 'Humidity', 'Temperature']:\n",
        "    train_df[col] = train_df[col].fillna(train_df[col].median())\n",
        "    test_df[col] = test_df[col].fillna(train_df[col].median())\n"
      ],
      "metadata": {
        "id": "_pHCSOhGOBUH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "label_cols = ['Apartment_Type', 'Income_Level', 'Amenities']\n",
        "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "\n",
        "# Fit on train only\n",
        "train_df[label_cols] = encoder.fit_transform(train_df[label_cols])\n",
        "test_df[label_cols] = encoder.transform(test_df[label_cols])\n"
      ],
      "metadata": {
        "id": "tJp0jn5iOYeU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_cols = ['Apartment_Type', 'Income_Level', 'Amenities']\n",
        "encoders = {}\n",
        "\n",
        "for col in label_cols:\n",
        "    # Convert both train and test to string\n",
        "    train_df[col] = train_df[col].astype(str)\n",
        "    test_df[col] = test_df[col].astype(str)\n",
        "\n",
        "    # Handle unseen labels in test by setting them to \"Unknown\"\n",
        "    train_labels = train_df[col].unique().tolist()\n",
        "    test_df[col] = test_df[col].apply(lambda x: x if x in train_labels else \"Unknown\")\n",
        "\n",
        "    # Add \"Unknown\" to training set (if not already there)\n",
        "    if \"Unknown\" not in train_labels:\n",
        "        train_df[col] = train_df[col].astype(str).replace(\"\", \"Unknown\")\n",
        "        train_df = pd.concat([train_df, pd.DataFrame({col: [\"Unknown\"]})], ignore_index=True)\n",
        "\n",
        "    # Fit encoder and transform\n",
        "    encoders[col] = LabelEncoder()\n",
        "    train_df[col] = encoders[col].fit_transform(train_df[col])\n",
        "    test_df[col] = encoders[col].transform(test_df[col])\n"
      ],
      "metadata": {
        "id": "ceV5Q7ptOvBc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.drop(columns=['Timestamp'])\n",
        "test_df = test_df.drop(columns=['Timestamp'])"
      ],
      "metadata": {
        "id": "NLRfa5vTPEvH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df.drop(columns=['Water_Consumption'])\n",
        "y_train = train_df['Water_Consumption']\n",
        "X_test = test_df.copy()  # Test has no Water_Consumption\n"
      ],
      "metadata": {
        "id": "LgpUaRUePfmx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = train_df.drop(columns=['Water_Consumption'])\n",
        "y = train_df['Water_Consumption']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "phNaPj0cPhEJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop any rows where Water_Consumption is missing\n",
        "train_df = train_df.dropna(subset=['Water_Consumption'])\n",
        "\n",
        "# Redefine X and y\n",
        "X = train_df.drop(columns=['Water_Consumption'])\n",
        "y = train_df['Water_Consumption']\n"
      ],
      "metadata": {
        "id": "85kg3pjBP9tT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Initialize and train\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_val)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "score = max(0, 100 - rmse)\n",
        "\n",
        "print(\"Validation RMSE:\", rmse)\n",
        "print(\"Custom Score:\", score)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypmXRPaFPrfI",
        "outputId": "6c05e561-2104-4182-b23c-19ca3072f7bb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation RMSE: 20.171381049219562\n",
            "Custom Score: 79.82861895078044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y)\n",
        "test_preds = model.predict(test_df)\n"
      ],
      "metadata": {
        "id": "8fh-2M3cPtHI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\n",
        "    \"Timestamp\": pd.read_csv(os.path.join(dataset_folder, \"test.csv\"))[\"Timestamp\"],\n",
        "    \"Water_Consumption\": test_preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "HGlfAW-pQG6o"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4gJhRWf8QI5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the text file (readme.txt)"
      ],
      "metadata": {
        "id": "QrRoG6tGQt12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explanation_text = \"\"\"Smart Water Monitoring - Machine Learning Challenge\n",
        "----------------------------------------------------\n",
        "\n",
        "Author: Sreenija Earanki\n",
        "\n",
        "Objective:\n",
        "----------\n",
        "To build a machine learning model that predicts daily water consumption per household using a variety of features such as household demographics, weather conditions, and behavioral patterns.\n",
        "\n",
        "Dataset Summary:\n",
        "----------------\n",
        "- train.csv (14,000 rows): Contains historical water consumption data along with 11 features.\n",
        "- test.csv (6,000 rows): Same features (except target).\n",
        "- sample_submission.csv: Shows the expected format of the final predictions.\n",
        "\n",
        "Target variable:\n",
        "----------------\n",
        "- Water_Consumption (float): Represents the total water consumed for a given 8-hour period.\n",
        "\n",
        "Approach:\n",
        "---------\n",
        "1. Exploratory Data Analysis & Cleaning\n",
        "   - Converted 'Timestamp' into datetime and extracted useful temporal features: `Hour`, `DayOfWeek`, `Month`.\n",
        "   - Identified and handled missing values using appropriate imputation:\n",
        "     - Categorical features (`Amenities`, `Apartment_Type`, `Income_Level`) filled with `'Unknown'` or mode.\n",
        "     - Numeric features (`Humidity`, `Temperature`, `Appliance_Usage`) filled using median imputation.\n",
        "   - Removed the original `Timestamp` column after extracting time features.\n",
        "\n",
        "2. Feature Engineering\n",
        "   - Extracted time-based features: `Hour`, `DayOfWeek`, and `Month` to capture daily and weekly patterns.\n",
        "   - Applied **Label Encoding** to categorical features (`Apartment_Type`, `Income_Level`, `Amenities`) for compatibility with tree-based models.\n",
        "\n",
        "3. Model Selection\n",
        "   - Chose **Random Forest Regressor** as the baseline model due to its robustness, ability to handle nonlinear relationships, and resilience to outliers and multicollinearity.\n",
        "   - Random Forest is particularly effective on tabular data and handles mixed data types (categorical + numerical) well after encoding.\n",
        "\n",
        "4. Training & Validation\n",
        "   - Split the training data (80/20) to evaluate model performance.\n",
        "   - Used **Root Mean Squared Error (RMSE)** as the evaluation metric, consistent with the competition's custom scoring formula.\n",
        "   - Achieved reasonable performance on validation set with limited hyperparameter tuning.\n",
        "\n",
        "5. Prediction\n",
        "   - Trained final model on the entire training dataset.\n",
        "   - Generated predictions on the test set.\n",
        "   - Constructed a submission file with predicted `Water_Consumption` values aligned with the correct `Timestamp` entries.\n",
        "\n",
        "Tools & Libraries:\n",
        "------------------\n",
        "- Python 3.x\n",
        "- pandas, numpy: Data manipulation and preprocessing\n",
        "- scikit-learn: Model building and evaluation\n",
        "  - RandomForestRegressor\n",
        "  - LabelEncoder\n",
        "  - train_test_split\n",
        "- zipfile: For packaging submission files\n",
        "\n",
        "Future Scope:\n",
        "-------------------------\n",
        "- Try more powerful models like XGBoost or LightGBM.\n",
        "- Hyperparameter tuning using GridSearchCV or RandomizedSearchCV.\n",
        "- Investigate temporal trends further with time series analysis techniques.\n",
        "- Explore SHAP or permutation feature importance to interpret model behavior.\n",
        "\n",
        "Submission Files:\n",
        "-----------------\n",
        "- submission.csv (prediction file)\n",
        "- explanation.txt (this file)\n",
        "- water.ipynb (source code)\n",
        "\"\"\"\n",
        "\n",
        "with open(\"explanation.txt\", \"w\") as f:\n",
        "    f.write(explanation_text)"
      ],
      "metadata": {
        "id": "kIw_txg8Qvm-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"source_files.zip\", \"w\") as zipf:\n",
        "    zipf.write(\"explanation.txt\")\n",
        "    zipf.write(\"submission.csv\")"
      ],
      "metadata": {
        "id": "EznqVr8ARSuq"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}